{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOmKqSldIRsLZjOo75TLbIn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"apkhqN4tiTdO"},"outputs":[],"source":[]},{"cell_type":"code","source":[],"metadata":{"id":"eCYrhJBIiUNx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","X2CT Data Preprocessing Module\n","CT와 X-ray 데이터를 전처리하고 HDF5 형식으로 저장\n","\"\"\"\n","\n","import os\n","import numpy as np\n","import h5py\n","import pydicom\n","import SimpleITK as sitk\n","from scipy.ndimage import zoom\n","import torch\n","from torchvision import transforms\n","\n","\n","class CTPreprocessor:\n","    \"\"\"CT DICOM 파일을 로드하고 전처리\"\"\"\n","\n","    def __init__(self, target_spacing=[1, 1, 1], target_size=256):\n","        self.target_spacing = target_spacing\n","        self.target_size = target_size\n","\n","    def load_ct_slices(self, ct_folder_path):\n","        \"\"\"DICOM 슬라이스들을 로드\"\"\"\n","        slices = []\n","        slice_thickness = None\n","        pixel_spacing = None\n","\n","        for filename in sorted(os.listdir(ct_folder_path)):\n","            if filename.endswith('.dcm'):\n","                filepath = os.path.join(ct_folder_path, filename)\n","                dicom_data = pydicom.dcmread(filepath)\n","\n","                if slice_thickness is None:\n","                    slice_thickness = float(dicom_data.SliceThickness)\n","                if pixel_spacing is None:\n","                    pixel_spacing = [float(i) for i in dicom_data.PixelSpacing]\n","\n","                slices.append(dicom_data.pixel_array)\n","\n","        ct_volume = np.stack(slices, axis=0)\n","        original_spacing = [slice_thickness] + pixel_spacing\n","        return ct_volume, original_spacing\n","\n","    def resample(self, image, spacing):\n","        \"\"\"이미지를 타겟 spacing으로 리샘플링\"\"\"\n","        spacing = np.array(spacing)\n","        new_spacing = np.array(self.target_spacing)\n","\n","        resize_factor = spacing / new_spacing\n","        new_shape = np.round(image.shape * resize_factor)\n","        real_resize_factor = new_shape / image.shape\n","        new_spacing = spacing / real_resize_factor\n","\n","        image = zoom(image, real_resize_factor, mode='nearest', order=1)\n","        return image, new_spacing\n","\n","    def crop_or_pad(self, volume, target_size):\n","        \"\"\"볼륨을 target_size로 크롭 또는 패딩\"\"\"\n","        d, h, w = volume.shape\n","\n","        # Depth\n","        if d >= target_size:\n","            start_d = (d - target_size) // 2\n","            volume = volume[start_d:start_d + target_size, :, :]\n","        else:\n","            pad_d = (target_size - d) // 2\n","            pad_d_end = target_size - d - pad_d\n","            volume = np.pad(volume, ((pad_d, pad_d_end), (0, 0), (0, 0)), mode='constant')\n","\n","        # Height\n","        d, h, w = volume.shape\n","        if h >= target_size:\n","            start_h = (h - target_size) // 2\n","            volume = volume[:, start_h:start_h + target_size, :]\n","        else:\n","            pad_h = (target_size - h) // 2\n","            pad_h_end = target_size - h - pad_h\n","            volume = np.pad(volume, ((0, 0), (pad_h, pad_h_end), (0, 0)), mode='constant')\n","\n","        # Width\n","        d, h, w = volume.shape\n","        if w >= target_size:\n","            start_w = (w - target_size) // 2\n","            volume = volume[:, :, start_w:start_w + target_size]\n","        else:\n","            pad_w = (target_size - w) // 2\n","            pad_w_end = target_size - w - pad_w\n","            volume = np.pad(volume, ((0, 0), (0, 0), (pad_w, pad_w_end)), mode='constant')\n","\n","        return volume\n","\n","    def normalize_ct(self, ct_volume, window_level=40, window_width=400):\n","        \"\"\"CT를 HU windowing 후 [-1, 1]로 정규화\"\"\"\n","        # HU windowing\n","        min_hu = window_level - window_width // 2\n","        max_hu = window_level + window_width // 2\n","\n","        ct_volume = np.clip(ct_volume, min_hu, max_hu)\n","        ct_volume = (ct_volume - min_hu) / (max_hu - min_hu)  # [0, 1]\n","        ct_volume = ct_volume * 2 - 1  # [-1, 1]\n","\n","        return ct_volume.astype(np.float32)\n","\n","    def preprocess(self, ct_folder_path):\n","        \"\"\"전체 전처리 파이프라인\"\"\"\n","        # 로드\n","        ct_volume, original_spacing = self.load_ct_slices(ct_folder_path)\n","        print(f\"Original shape: {ct_volume.shape}, spacing: {original_spacing}\")\n","\n","        # 리샘플링\n","        ct_volume, new_spacing = self.resample(ct_volume, original_spacing)\n","        print(f\"After resample: {ct_volume.shape}, spacing: {new_spacing}\")\n","\n","        # 크롭/패딩\n","        ct_volume = self.crop_or_pad(ct_volume, self.target_size)\n","        print(f\"After crop/pad: {ct_volume.shape}\")\n","\n","        # 정규화\n","        ct_volume = self.normalize_ct(ct_volume)\n","        print(f\"After normalize: min={ct_volume.min():.2f}, max={ct_volume.max():.2f}\")\n","\n","        return ct_volume\n","\n","\n","class XRayPreprocessor:\n","    \"\"\"X-ray DICOM 파일을 로드하고 전처리\"\"\"\n","\n","    def __init__(self, target_size=256):\n","        self.target_size = target_size\n","\n","    def load_xray(self, xray_path):\n","        \"\"\"단일 X-ray DICOM 파일 로드\"\"\"\n","        dicom_data = pydicom.dcmread(xray_path)\n","        xray_image = dicom_data.pixel_array.astype(np.float32)\n","        return xray_image\n","\n","    def resize_xray(self, xray_image):\n","        \"\"\"X-ray를 target_size로 리사이즈\"\"\"\n","        from scipy.ndimage import zoom\n","\n","        h, w = xray_image.shape\n","        zoom_factors = (self.target_size / h, self.target_size / w)\n","        xray_image = zoom(xray_image, zoom_factors, order=1)\n","\n","        return xray_image\n","\n","    def normalize_xray(self, xray_image):\n","        \"\"\"X-ray를 [-1, 1]로 정규화\"\"\"\n","        xray_image = xray_image - xray_image.min()\n","        xray_image = xray_image / (xray_image.max() + 1e-8)  # [0, 1]\n","        xray_image = xray_image * 2 - 1  # [-1, 1]\n","\n","        return xray_image.astype(np.float32)\n","\n","    def preprocess(self, xray_path):\n","        \"\"\"전체 전처리 파이프라인\"\"\"\n","        xray_image = self.load_xray(xray_path)\n","        print(f\"Original X-ray shape: {xray_image.shape}\")\n","\n","        xray_image = self.resize_xray(xray_image)\n","        print(f\"After resize: {xray_image.shape}\")\n","\n","        xray_image = self.normalize_xray(xray_image)\n","        print(f\"After normalize: min={xray_image.min():.2f}, max={xray_image.max():.2f}\")\n","\n","        return xray_image\n","\n","\n","class HDF5DataCreator:\n","    \"\"\"전처리된 데이터를 HDF5 형식으로 저장\"\"\"\n","\n","    def __init__(self, output_path):\n","        self.output_path = output_path\n","\n","    def create_hdf5(self, ct_volume, xray_front, xray_side, patient_id):\n","        \"\"\"HDF5 파일 생성\"\"\"\n","        with h5py.File(self.output_path, 'w') as f:\n","            f.create_dataset('ct', data=ct_volume, compression='gzip')\n","            f.create_dataset('xray_front', data=xray_front, compression='gzip')\n","            f.create_dataset('xray_side', data=xray_side, compression='gzip')\n","            f.attrs['patient_id'] = patient_id\n","            f.attrs['ct_shape'] = ct_volume.shape\n","            f.attrs['xray_shape'] = xray_front.shape\n","\n","        print(f\"HDF5 file created: {self.output_path}\")\n","\n","\n","# 사용 예시\n","if __name__ == \"__main__\":\n","    # CT 전처리\n","    ct_preprocessor = CTPreprocessor(target_size=256)\n","    ct_volume = ct_preprocessor.preprocess(\n","        '/content/drive/MyDrive/LIDC-IDRI/LIDC-IDRI-0001/01-01-2000-NA-NA-30178/3000566.000000-NA-03192'\n","    )\n","\n","    # X-ray 전처리\n","    xray_preprocessor = XRayPreprocessor(target_size=256)\n","    xray_front = xray_preprocessor.preprocess(\n","        '/content/drive/MyDrive/LIDC-IDRI/LIDC-IDRI-0001/01-01-2000-NA-NA-35511/3000923.000000-NA-62357/1-1.dcm'\n","    )\n","    xray_side = xray_preprocessor.preprocess(\n","        '/content/drive/MyDrive/LIDC-IDRI/LIDC-IDRI-0001/01-01-2000-NA-NA-35511/3000923.000000-NA-62357/1-2.dcm'\n","    )\n","\n","    # HDF5 저장\n","    hdf5_creator = HDF5DataCreator('/content/drive/MyDrive/processed_data/patient_0001.h5')\n","    hdf5_creator.create_hdf5(ct_volume, xray_front, xray_side, 'LIDC-IDRI-0001')\n","\n","    print(\"\\n✅ 데이터 전처리 완료!\")"],"metadata":{"id":"lsd-IoIPiUQ_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","X2CT Network Architectures\n","Generator와 Discriminator 정의 (X2CT 논문 기반)\n","\"\"\"\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import functools\n","\n","\n","# ============================================================================\n","# Basic Building Blocks\n","# ============================================================================\n","\n","class ResnetBlock2D(nn.Module):\n","    \"\"\"2D Resnet Block\"\"\"\n","\n","    def __init__(self, dim, norm_layer=nn.BatchNorm2d, use_dropout=False):\n","        super(ResnetBlock2D, self).__init__()\n","\n","        layers = [\n","            nn.Conv2d(dim, dim, kernel_size=3, padding=1, bias=False),\n","            norm_layer(dim),\n","            nn.ReLU(True),\n","        ]\n","\n","        if use_dropout:\n","            layers.append(nn.Dropout(0.5))\n","\n","        layers += [\n","            nn.Conv2d(dim, dim, kernel_size=3, padding=1, bias=False),\n","            norm_layer(dim),\n","        ]\n","\n","        self.conv_block = nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        return x + self.conv_block(x)\n","\n","\n","class ResnetBlock3D(nn.Module):\n","    \"\"\"3D Resnet Block\"\"\"\n","\n","    def __init__(self, dim, norm_layer=nn.BatchNorm3d, use_dropout=False):\n","        super(ResnetBlock3D, self).__init__()\n","\n","        layers = [\n","            nn.Conv3d(dim, dim, kernel_size=3, padding=1, bias=False),\n","            norm_layer(dim),\n","            nn.ReLU(True),\n","        ]\n","\n","        if use_dropout:\n","            layers.append(nn.Dropout(0.5))\n","\n","        layers += [\n","            nn.Conv3d(dim, dim, kernel_size=3, padding=1, bias=False),\n","            norm_layer(dim),\n","        ]\n","\n","        self.conv_block = nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        return x + self.conv_block(x)\n","\n","\n","# ============================================================================\n","# 2D Encoder (X-ray → 2D Features)\n","# ============================================================================\n","\n","class Encoder2D(nn.Module):\n","    \"\"\"\n","    2D Encoder for X-ray images\n","    입력: [B, 1, 256, 256]\n","    출력: [B, 512, 16, 16]\n","    \"\"\"\n","\n","    def __init__(self, input_nc=1, ngf=64, n_downsampling=4, norm_layer=nn.BatchNorm2d):\n","        super(Encoder2D, self).__init__()\n","\n","        # Initial convolution\n","        model = [\n","            nn.Conv2d(input_nc, ngf, kernel_size=7, padding=3, bias=False),\n","            norm_layer(ngf),\n","            nn.ReLU(True)\n","        ]\n","\n","        # Downsampling\n","        for i in range(n_downsampling):\n","            mult = 2 ** i\n","            model += [\n","                nn.Conv2d(ngf * mult, ngf * mult * 2, kernel_size=3, stride=2, padding=1, bias=False),\n","                norm_layer(ngf * mult * 2),\n","                nn.ReLU(True)\n","            ]\n","\n","        # Resnet blocks\n","        mult = 2 ** n_downsampling\n","        for i in range(2):\n","            model += [ResnetBlock2D(ngf * mult, norm_layer=norm_layer)]\n","\n","        self.model = nn.Sequential(*model)\n","        self.output_nc = ngf * mult\n","\n","    def forward(self, x):\n","        return self.model(x)\n","\n","\n","# ============================================================================\n","# Connection Modules (2D → 3D dimension lifting)\n","# ============================================================================\n","\n","class ConnectionB(nn.Module):\n","    \"\"\"\n","    Connection-B: 2D feature를 3D로 확장\n","    [B, C, H, W] → [B, C, D, H, W]\n","    \"\"\"\n","\n","    def __init__(self, in_channels, depth=256):\n","        super(ConnectionB, self).__init__()\n","        self.depth = depth\n","\n","        # 3D convolution for dimension expansion\n","        self.expand_conv = nn.Sequential(\n","            nn.Conv3d(in_channels, in_channels, kernel_size=3, padding=1, bias=False),\n","            nn.BatchNorm3d(in_channels),\n","            nn.ReLU(True)\n","        )\n","\n","    def forward(self, x):\n","        \"\"\"\n","        x: [B, C, H, W]\n","        return: [B, C, D, H, W]\n","        \"\"\"\n","        B, C, H, W = x.shape\n","\n","        # Expand along depth dimension\n","        x = x.unsqueeze(2)  # [B, C, 1, H, W]\n","        x = x.repeat(1, 1, self.depth, 1, 1)  # [B, C, D, H, W]\n","\n","        # Refine with 3D conv\n","        x = self.expand_conv(x)\n","\n","        return x\n","\n","\n","class ConnectionC(nn.Module):\n","    \"\"\"\n","    Connection-C: Multi-view fusion\n","    두 개의 직교 뷰를 3D 공간에서 융합\n","    \"\"\"\n","\n","    def __init__(self, channels):\n","        super(ConnectionC, self).__init__()\n","\n","        self.fusion_conv = nn.Sequential(\n","            nn.Conv3d(channels * 2, channels, kernel_size=3, padding=1, bias=False),\n","            nn.BatchNorm3d(channels),\n","            nn.ReLU(True),\n","            nn.Conv3d(channels, channels, kernel_size=3, padding=1, bias=False),\n","            nn.BatchNorm3d(channels),\n","            nn.ReLU(True)\n","        )\n","\n","    def forward(self, view1, view2):\n","        \"\"\"\n","        view1: [B, C, D, H, W] - PA view\n","        view2: [B, C, D, H, W] - Lateral view (depth와 height가 교환됨)\n","        \"\"\"\n","        # view2를 회전: depth ↔ height\n","        view2_rotated = view2.permute(0, 1, 3, 2, 4)  # [B, C, H, D, W]\n","\n","        # 크기 맞추기\n","        if view1.shape != view2_rotated.shape:\n","            view2_rotated = F.interpolate(\n","                view2_rotated,\n","                size=view1.shape[2:],\n","                mode='trilinear',\n","                align_corners=False\n","            )\n","\n","        # Concatenate and fuse\n","        fused = torch.cat([view1, view2_rotated], dim=1)\n","        output = self.fusion_conv(fused)\n","\n","        return output\n","\n","\n","# ============================================================================\n","# 3D Decoder (3D Features → CT Volume)\n","# ============================================================================\n","\n","class Decoder3D(nn.Module):\n","    \"\"\"\n","    3D Decoder for CT volume generation\n","    입력: [B, 512, 16, 16, 16]\n","    출력: [B, 1, 256, 256, 256]\n","    \"\"\"\n","\n","    def __init__(self, input_nc=512, output_nc=1, ngf=64, n_upsampling=4, norm_layer=nn.BatchNorm3d):\n","        super(Decoder3D, self).__init__()\n","\n","        model = []\n","\n","        # Resnet blocks\n","        for i in range(2):\n","            model += [ResnetBlock3D(input_nc, norm_layer=norm_layer)]\n","\n","        # Upsampling\n","        for i in range(n_upsampling):\n","            mult = 2 ** (n_upsampling - i)\n","            model += [\n","                nn.ConvTranspose3d(ngf * mult, int(ngf * mult / 2),\n","                                   kernel_size=4, stride=2, padding=1, bias=False),\n","                norm_layer(int(ngf * mult / 2)),\n","                nn.ReLU(True)\n","            ]\n","\n","        # Output layer\n","        model += [\n","            nn.Conv3d(ngf, output_nc, kernel_size=7, padding=3),\n","            nn.Tanh()\n","        ]\n","\n","        self.model = nn.Sequential(*model)\n","\n","    def forward(self, x):\n","        return self.model(x)\n","\n","\n","# ============================================================================\n","# Generator (Complete X2CT-GAN Generator)\n","# ============================================================================\n","\n","class X2CTGenerator(nn.Module):\n","    \"\"\"\n","    X2CT-GAN Generator\n","    두 개의 직교 X-ray 이미지로부터 3D CT 볼륨 생성\n","    \"\"\"\n","\n","    def __init__(self, input_nc=1, output_nc=1, ngf=64, depth=256):\n","        super(X2CTGenerator, self).__init__()\n","\n","        # 각 뷰를 위한 2D 인코더\n","        self.encoder_view1 = Encoder2D(input_nc, ngf, n_downsampling=4)\n","        self.encoder_view2 = Encoder2D(input_nc, ngf, n_downsampling=4)\n","\n","        # 2D → 3D 확장 (Connection-B)\n","        encoder_output_nc = ngf * 16  # 2^4 = 16\n","        self.connection_b_view1 = ConnectionB(encoder_output_nc, depth=depth//16)\n","        self.connection_b_view2 = ConnectionB(encoder_output_nc, depth=depth//16)\n","\n","        # Multi-view fusion (Connection-C)\n","        self.connection_c = ConnectionC(encoder_output_nc)\n","\n","        # 3D 디코더\n","        self.decoder = Decoder3D(encoder_output_nc, output_nc, ngf, n_upsampling=4)\n","\n","    def forward(self, x):\n","        \"\"\"\n","        x: list of [view1, view2]\n","        view1: [B, 1, 256, 256] - PA X-ray\n","        view2: [B, 1, 256, 256] - Lateral X-ray\n","        return: [B, 1, 256, 256, 256] - CT volume\n","        \"\"\"\n","        if not isinstance(x, list) or len(x) != 2:\n","            raise ValueError(\"Input must be a list of [view1, view2]\")\n","\n","        view1, view2 = x\n","\n","        # 2D encoding\n","        feat1 = self.encoder_view1(view1)  # [B, 512, 16, 16]\n","        feat2 = self.encoder_view2(view2)  # [B, 512, 16, 16]\n","\n","        # 2D → 3D expansion\n","        feat1_3d = self.connection_b_view1(feat1)  # [B, 512, 16, 16, 16]\n","        feat2_3d = self.connection_b_view2(feat2)  # [B, 512, 16, 16, 16]\n","\n","        # Multi-view fusion\n","        fused = self.connection_c(feat1_3d, feat2_3d)  # [B, 512, 16, 16, 16]\n","\n","        # 3D decoding\n","        output = self.decoder(fused)  # [B, 1, 256, 256, 256]\n","\n","        return output\n","\n","\n","# ============================================================================\n","# Discriminator (3D PatchGAN)\n","# ============================================================================\n","\n","class X2CTDiscriminator(nn.Module):\n","    \"\"\"\n","    3D PatchGAN Discriminator\n","    입력: [B, 1, 256, 256, 256] (CT volume only)\n","    \"\"\"\n","\n","    def __init__(self, input_nc=1, ndf=64, n_layers=3, norm_layer=nn.BatchNorm3d):\n","        super(X2CTDiscriminator, self).__init__()\n","\n","        if type(norm_layer) == functools.partial:\n","            use_bias = norm_layer.func == nn.InstanceNorm3d\n","        else:\n","            use_bias = norm_layer == nn.InstanceNorm3d\n","\n","        kw = 4\n","        padw = 1\n","\n","        sequence = [\n","            nn.Conv3d(input_nc, ndf, kernel_size=kw, stride=2, padding=padw),\n","            nn.LeakyReLU(0.2, True)\n","        ]\n","\n","        nf_mult = 1\n","        nf_mult_prev = 1\n","        for n in range(1, n_layers):\n","            nf_mult_prev = nf_mult\n","            nf_mult = min(2 ** n, 8)\n","            sequence += [\n","                nn.Conv3d(ndf * nf_mult_prev, ndf * nf_mult,\n","                          kernel_size=kw, stride=2, padding=padw, bias=use_bias),\n","                norm_layer(ndf * nf_mult),\n","                nn.LeakyReLU(0.2, True)\n","            ]\n","\n","        nf_mult_prev = nf_mult\n","        nf_mult = min(2 ** n_layers, 8)\n","        sequence += [\n","            nn.Conv3d(ndf * nf_mult_prev, ndf * nf_mult,\n","                      kernel_size=kw, stride=1, padding=padw, bias=use_bias),\n","            norm_layer(ndf * nf_mult),\n","            nn.LeakyReLU(0.2, True)\n","        ]\n","\n","        sequence += [\n","            nn.Conv3d(ndf * nf_mult, 1, kernel_size=kw, stride=1, padding=padw)\n","        ]\n","\n","        self.model = nn.Sequential(*sequence)\n","\n","    def forward(self, input):\n","        \"\"\"\n","        input: [B, 1, D, H, W]\n","        return: [B, 1, ...]\n","        \"\"\"\n","        return self.model(input)\n","\n","\n","# ============================================================================\n","# 테스트\n","# ============================================================================\n","\n","if __name__ == \"__main__\":\n","    print(\"Testing X2CT Networks...\")\n","\n","    # Generator test\n","    generator = X2CTGenerator(input_nc=1, output_nc=1, ngf=64, depth=256)\n","    view1 = torch.randn(1, 1, 256, 256)\n","    view2 = torch.randn(1, 1, 256, 256)\n","\n","    print(f\"\\nGenerator Input:\")\n","    print(f\"  View1: {view1.shape}\")\n","    print(f\"  View2: {view2.shape}\")\n","\n","    fake_ct = generator([view1, view2])\n","    print(f\"\\nGenerator Output:\")\n","    print(f\"  Fake CT: {fake_ct.shape}\")\n","\n","    # Discriminator test\n","    discriminator = X2CTDiscriminator(input_nc=1, ndf=64, n_layers=3)\n","    pred = discriminator(fake_ct)\n","    print(f\"\\nDiscriminator Output:\")\n","    print(f\"  Prediction: {pred.shape}\")\n","\n","    # Parameter count\n","    gen_params = sum(p.numel() for p in generator.parameters())\n","    disc_params = sum(p.numel() for p in discriminator.parameters())\n","    print(f\"\\n✅ Networks initialized successfully!\")\n","    print(f\"Generator parameters: {gen_params:,}\")\n","    print(f\"Discriminator parameters: {disc_params:,}\")"],"metadata":{"id":"iHhKDKyEjthU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","X2CT Loss Functions and Dataset\n","GAN Loss, Reconstruction Loss, Dataset 정의\n","\"\"\"\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset\n","import h5py\n","import numpy as np\n","import random\n","\n","\n","# ============================================================================\n","# Loss Functions\n","# ============================================================================\n","\n","class GANLoss(nn.Module):\n","    \"\"\"\n","    GAN Loss (LSGAN)\n","    \"\"\"\n","\n","    def __init__(self, use_lsgan=True, target_real_label=1.0, target_fake_label=0.0):\n","        super(GANLoss, self).__init__()\n","        self.register_buffer('real_label', torch.tensor(target_real_label))\n","        self.register_buffer('fake_label', torch.tensor(target_fake_label))\n","\n","        if use_lsgan:\n","            self.loss = nn.MSELoss()\n","        else:\n","            self.loss = nn.BCEWithLogitsLoss()\n","\n","    def get_target_tensor(self, input, target_is_real):\n","        if target_is_real:\n","            target_tensor = self.real_label\n","        else:\n","            target_tensor = self.fake_label\n","\n","        return target_tensor.expand_as(input)\n","\n","    def __call__(self, input, target_is_real):\n","        target_tensor = self.get_target_tensor(input, target_is_real)\n","        loss = self.loss(input, target_tensor)\n","        return loss\n","\n","\n","class ReconstructionLoss(nn.Module):\n","    \"\"\"\n","    Reconstruction Loss (L1 or L2)\n","    \"\"\"\n","\n","    def __init__(self, loss_type='l1'):\n","        super(ReconstructionLoss, self).__init__()\n","        if loss_type == 'l1':\n","            self.loss = nn.L1Loss()\n","        elif loss_type == 'l2':\n","            self.loss = nn.MSELoss()\n","        else:\n","            raise ValueError(f\"Unsupported loss type: {loss_type}\")\n","\n","    def __call__(self, pred, target):\n","        return self.loss(pred, target)\n","\n","\n","class ProjectionLoss(nn.Module):\n","    \"\"\"\n","    Projection Loss (optional)\n","    생성된 3D CT를 2D로 투영하여 입력 X-ray와 비교\n","    \"\"\"\n","\n","    def __init__(self):\n","        super(ProjectionLoss, self).__init__()\n","        self.loss = nn.L1Loss()\n","\n","    def forward(self, ct_volume, xray_front, xray_side):\n","        \"\"\"\n","        ct_volume: [B, 1, D, H, W]\n","        xray_front: [B, 1, H, W]\n","        xray_side: [B, 1, H, W]\n","        \"\"\"\n","        # DRR simulation (simple average projection)\n","        # Front view (average over width dimension)\n","        drr_front = torch.mean(ct_volume, dim=4)  # [B, 1, D, H]\n","        drr_front = torch.mean(drr_front, dim=2)  # [B, 1, H]\n","        drr_front = drr_front.unsqueeze(2)  # [B, 1, 1, H]\n","        drr_front = drr_front.repeat(1, 1, xray_front.shape[2], 1)  # [B, 1, H, H]\n","\n","        # Side view (average over depth dimension)\n","        drr_side = torch.mean(ct_volume, dim=2)  # [B, 1, H, W]\n","\n","        # Resize to match X-ray size\n","        if drr_front.shape != xray_front.shape:\n","            drr_front = F.interpolate(drr_front, size=xray_front.shape[2:],\n","                                      mode='bilinear', align_corners=False)\n","        if drr_side.shape != xray_side.shape:\n","            drr_side = F.interpolate(drr_side, size=xray_side.shape[2:],\n","                                     mode='bilinear', align_corners=False)\n","\n","        loss_front = self.loss(drr_front, xray_front)\n","        loss_side = self.loss(drr_side, xray_side)\n","\n","        return loss_front + loss_side\n","\n","\n","# ============================================================================\n","# Image Pool (for stable training)\n","# ============================================================================\n","\n","class ImagePool:\n","    \"\"\"\n","    이미지 풀: 과거 생성된 이미지를 저장하고 랜덤으로 반환\n","    Discriminator 학습 안정화\n","    \"\"\"\n","\n","    def __init__(self, pool_size):\n","        self.pool_size = pool_size\n","        if self.pool_size > 0:\n","            self.num_imgs = 0\n","            self.images = []\n","\n","    def query(self, images):\n","        if self.pool_size == 0:\n","            return images\n","\n","        return_images = []\n","        for image in images:\n","            image = torch.unsqueeze(image.data, 0)\n","            if self.num_imgs < self.pool_size:\n","                self.num_imgs += 1\n","                self.images.append(image)\n","                return_images.append(image)\n","            else:\n","                p = random.uniform(0, 1)\n","                if p > 0.5:\n","                    random_id = random.randint(0, self.pool_size - 1)\n","                    tmp = self.images[random_id].clone()\n","                    self.images[random_id] = image\n","                    return_images.append(tmp)\n","                else:\n","                    return_images.append(image)\n","\n","        return_images = torch.cat(return_images, 0)\n","        return return_images\n","\n","\n","# ============================================================================\n","# Dataset\n","# ============================================================================\n","\n","class X2CTDataset(Dataset):\n","    \"\"\"\n","    X2CT Dataset for HDF5 files\n","    각 샘플: CT volume + 2 X-ray images\n","    \"\"\"\n","\n","    def __init__(self, data_root, file_list, phase='train', target_size=256):\n","        \"\"\"\n","        Args:\n","            data_root: HDF5 파일들이 있는 디렉토리\n","            file_list: 파일 리스트 (.txt)\n","            phase: 'train' or 'test'\n","            target_size: 목표 크기\n","        \"\"\"\n","        self.data_root = data_root\n","        self.phase = phase\n","        self.target_size = target_size\n","\n","        # Load file list\n","        with open(file_list, 'r') as f:\n","            self.file_paths = [line.strip() for line in f.readlines()]\n","\n","        print(f\"Loaded {len(self.file_paths)} samples for {phase}\")\n","\n","    def __len__(self):\n","        return len(self.file_paths)\n","\n","    def __getitem__(self, idx):\n","        file_path = self.file_paths[idx]\n","\n","        # Load HDF5\n","        with h5py.File(file_path, 'r') as f:\n","            ct = f['ct'][:]\n","            xray_front = f['xray_front'][:]\n","            xray_side = f['xray_side'][:]\n","\n","        # Convert to torch tensors\n","        ct = torch.from_numpy(ct).float().unsqueeze(0)  # [1, D, H, W]\n","        xray_front = torch.from_numpy(xray_front).float().unsqueeze(0)  # [1, H, W]\n","        xray_side = torch.from_numpy(xray_side).float().unsqueeze(0)  # [1, H, W]\n","\n","        # Data augmentation (only for training)\n","        if self.phase == 'train':\n","            # Random flip\n","            if random.random() > 0.5:\n","                ct = torch.flip(ct, [3])  # Flip width\n","                xray_front = torch.flip(xray_front, [2])\n","\n","            # Random rotation (small angle)\n","            # (생략 - 필요시 추가)\n","\n","        return {\n","            'ct': ct,\n","            'xray_front': xray_front,\n","            'xray_side': xray_side,\n","            'path': file_path\n","        }\n","\n","\n","class SimpleX2CTDataset(Dataset):\n","    \"\"\"\n","    Simplified X2CT Dataset for single sample testing\n","    단일 샘플로 빠른 테스트용\n","    \"\"\"\n","\n","    def __init__(self, ct_volume, xray_front, xray_side):\n","        \"\"\"\n","        Args:\n","            ct_volume: numpy array [D, H, W]\n","            xray_front: numpy array [H, W]\n","            xray_side: numpy array [H, W]\n","        \"\"\"\n","        self.ct = torch.from_numpy(ct_volume).float().unsqueeze(0)\n","        self.xray_front = torch.from_numpy(xray_front).float().unsqueeze(0)\n","        self.xray_side = torch.from_numpy(xray_side).float().unsqueeze(0)\n","\n","    def __len__(self):\n","        return 1\n","\n","    def __getitem__(self, idx):\n","        return {\n","            'ct': self.ct,\n","            'xray_front': self.xray_front,\n","            'xray_side': self.xray_side,\n","            'path': 'single_sample'\n","        }\n","\n","\n","# ============================================================================\n","# Metrics\n","# ============================================================================\n","\n","def compute_psnr(img1, img2, max_val=1.0):\n","    \"\"\"Peak Signal-to-Noise Ratio\"\"\"\n","    mse = torch.mean((img1 - img2) ** 2)\n","    if mse == 0:\n","        return float('inf')\n","    psnr = 20 * torch.log10(max_val / torch.sqrt(mse))\n","    return psnr.item()\n","\n","\n","def compute_mse(img1, img2):\n","    \"\"\"Mean Squared Error\"\"\"\n","    mse = torch.mean((img1 - img2) ** 2)\n","    return mse.item()\n","\n","\n","def compute_mae(img1, img2):\n","    \"\"\"Mean Absolute Error\"\"\"\n","    mae = torch.mean(torch.abs(img1 - img2))\n","    return mae.item()\n","\n","\n","def compute_ssim(img1, img2, window_size=11):\n","    \"\"\"\n","    Structural Similarity Index (simplified version)\n","    실제 사용시 pytorch-msssim 패키지 권장\n","    \"\"\"\n","    # Simple implementation\n","    mu1 = torch.mean(img1)\n","    mu2 = torch.mean(img2)\n","\n","    sigma1_sq = torch.var(img1)\n","    sigma2_sq = torch.var(img2)\n","    sigma12 = torch.mean((img1 - mu1) * (img2 - mu2))\n","\n","    C1 = 0.01 ** 2\n","    C2 = 0.03 ** 2\n","\n","    ssim = ((2 * mu1 * mu2 + C1) * (2 * sigma12 + C2)) / \\\n","           ((mu1 ** 2 + mu2 ** 2 + C1) * (sigma1_sq + sigma2_sq + C2))\n","\n","    return ssim.item()\n","\n","\n","# ============================================================================\n","# 테스트\n","# ============================================================================\n","\n","if __name__ == \"__main__\":\n","    print(\"Testing Loss Functions and Dataset...\")\n","\n","    # Loss functions test\n","    gan_loss = GANLoss(use_lsgan=True)\n","    recon_loss = ReconstructionLoss(loss_type='l1')\n","    proj_loss = ProjectionLoss()\n","\n","    # Dummy data\n","    fake_pred = torch.randn(2, 1, 8, 8, 8)\n","    real_pred = torch.randn(2, 1, 8, 8, 8)\n","    fake_ct = torch.randn(2, 1, 256, 256, 256)\n","    real_ct = torch.randn(2, 1, 256, 256, 256)\n","    xray_front = torch.randn(2, 1, 256, 256)\n","    xray_side = torch.randn(2, 1, 256, 256)\n","\n","    # Test losses\n","    loss_gan_fake = gan_loss(fake_pred, False)\n","    loss_gan_real = gan_loss(real_pred, True)\n","    loss_recon = recon_loss(fake_ct, real_ct)\n","    loss_proj = proj_loss(fake_ct, xray_front, xray_side)\n","\n","    print(f\"\\nLoss values:\")\n","    print(f\"  GAN loss (fake): {loss_gan_fake.item():.4f}\")\n","    print(f\"  GAN loss (real): {loss_gan_real.item():.4f}\")\n","    print(f\"  Reconstruction loss: {loss_recon.item():.4f}\")\n","    print(f\"  Projection loss: {loss_proj.item():.4f}\")\n","\n","    # Test metrics\n","    psnr = compute_psnr(fake_ct, real_ct)\n","    mse = compute_mse(fake_ct, real_ct)\n","    mae = compute_mae(fake_ct, real_ct)\n","    ssim = compute_ssim(fake_ct, real_ct)\n","\n","    print(f\"\\nMetrics:\")\n","    print(f\"  PSNR: {psnr:.2f} dB\")\n","    print(f\"  MSE: {mse:.4f}\")\n","    print(f\"  MAE: {mae:.4f}\")\n","    print(f\"  SSIM: {ssim:.4f}\")\n","\n","    print(f\"\\n✅ Loss functions and metrics working!\")"],"metadata":{"id":"VKYvt7x0jtqq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","X2CTGAN Model\n","Generator와 Discriminator를 통합한 전체 GAN 모델\n","\"\"\"\n","\n","import torch\n","import torch.nn as nn\n","from torch.optim import Adam\n","import os\n","\n","\n","class X2CTGAN(nn.Module):\n","    \"\"\"\n","    X2CT-GAN Model\n","    Generator와 Discriminator를 관리하고 학습/추론 수행\n","    \"\"\"\n","\n","    def __init__(self, opt, generator, discriminator):\n","        super(X2CTGAN, self).__init__()\n","        self.opt = opt\n","        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","        # Networks\n","        self.netG = generator.to(self.device)\n","        self.netD = discriminator.to(self.device)\n","\n","        # Loss functions (import from losses_and_dataset.py)\n","        from losses_and_dataset import GANLoss, ReconstructionLoss, ProjectionLoss\n","\n","        self.criterionGAN = GANLoss(use_lsgan=True).to(self.device)\n","        self.criterionL1 = ReconstructionLoss(loss_type='l1').to(self.device)\n","        self.criterionProj = ProjectionLoss().to(self.device) if opt.use_proj_loss else None\n","\n","        # Optimizers\n","        self.optimizer_G = Adam(\n","            self.netG.parameters(),\n","            lr=opt.lr_G,\n","            betas=(opt.beta1, opt.beta2)\n","        )\n","        self.optimizer_D = Adam(\n","            self.netD.parameters(),\n","            lr=opt.lr_D,\n","            betas=(opt.beta1, opt.beta2)\n","        )\n","\n","        # Image pool for discriminator\n","        from losses_and_dataset import ImagePool\n","        self.fake_pool = ImagePool(opt.pool_size)\n","\n","        # For storing losses\n","        self.loss_D = 0\n","        self.loss_G_GAN = 0\n","        self.loss_G_L1 = 0\n","        self.loss_G_Proj = 0\n","        self.loss_G = 0\n","\n","    def set_input(self, input_data):\n","        \"\"\"입력 데이터 설정\"\"\"\n","        self.xray_front = input_data['xray_front'].to(self.device)\n","        self.xray_side = input_data['xray_side'].to(self.device)\n","        self.ct_real = input_data['ct'].to(self.device)\n","\n","    def forward(self):\n","        \"\"\"Generator forward pass\"\"\"\n","        self.ct_fake = self.netG([self.xray_front, self.xray_side])\n","\n","    def backward_D(self):\n","        \"\"\"Discriminator backward pass\"\"\"\n","        # Real CT\n","        pred_real = self.netD(self.ct_real)\n","        loss_D_real = self.criterionGAN(pred_real, True)\n","\n","        # Fake CT\n","        ct_fake = self.fake_pool.query(self.ct_fake)\n","        pred_fake = self.netD(ct_fake.detach())\n","        loss_D_fake = self.criterionGAN(pred_fake, False)\n","\n","        # Combined loss\n","        self.loss_D = (loss_D_real + loss_D_fake) * 0.5\n","        self.loss_D.backward()\n","\n","    def backward_G(self):\n","        \"\"\"Generator backward pass\"\"\"\n","        # GAN loss\n","        pred_fake = self.netD(self.ct_fake)\n","        self.loss_G_GAN = self.criterionGAN(pred_fake, True) * self.opt.lambda_GAN\n","\n","        # Reconstruction loss (L1)\n","        self.loss_G_L1 = self.criterionL1(self.ct_fake, self.ct_real) * self.opt.lambda_L1\n","\n","        # Projection loss (optional)\n","        if self.criterionProj is not None:\n","            self.loss_G_Proj = self.criterionProj(\n","                self.ct_fake,\n","                self.xray_front,\n","                self.xray_side\n","            ) * self.opt.lambda_Proj\n","        else:\n","            self.loss_G_Proj = 0\n","\n","        # Total generator loss\n","        self.loss_G = self.loss_G_GAN + self.loss_G_L1 + self.loss_G_Proj\n","        self.loss_G.backward()\n","\n","    def optimize_parameters(self):\n","        \"\"\"한 스텝 최적화\"\"\"\n","        # Forward\n","        self.forward()\n","\n","        # Update G\n","        self.set_requires_grad(self.netD, False)\n","        self.optimizer_G.zero_grad()\n","        self.backward_G()\n","        self.optimizer_G.step()\n","\n","        # Update D\n","        self.set_requires_grad(self.netD, True)\n","        self.optimizer_D.zero_grad()\n","        self.backward_D()\n","        self.optimizer_D.step()\n","\n","    def set_requires_grad(self, nets, requires_grad=False):\n","        \"\"\"네트워크의 gradient 계산 on/off\"\"\"\n","        if not isinstance(nets, list):\n","            nets = [nets]\n","        for net in nets:\n","            if net is not None:\n","                for param in net.parameters():\n","                    param.requires_grad = requires_grad\n","\n","    def get_current_losses(self):\n","        \"\"\"현재 loss 값들 반환\"\"\"\n","        return {\n","            'D': self.loss_D.item() if isinstance(self.loss_D, torch.Tensor) else self.loss_D,\n","            'G_GAN': self.loss_G_GAN.item(),\n","            'G_L1': self.loss_G_L1.item(),\n","            'G_Proj': self.loss_G_Proj.item() if isinstance(self.loss_G_Proj, torch.Tensor) else 0,\n","            'G': self.loss_G.item()\n","        }\n","\n","    def get_current_visuals(self):\n","        \"\"\"시각화를 위한 이미지들 반환\"\"\"\n","        return {\n","            'xray_front': self.xray_front,\n","            'xray_side': self.xray_side,\n","            'ct_real': self.ct_real,\n","            'ct_fake': self.ct_fake\n","        }\n","\n","    def save_networks(self, epoch, save_dir):\n","        \"\"\"네트워크 저장\"\"\"\n","        os.makedirs(save_dir, exist_ok=True)\n","\n","        save_path_G = os.path.join(save_dir, f'netG_epoch_{epoch}.pth')\n","        save_path_D = os.path.join(save_dir, f'netD_epoch_{epoch}.pth')\n","\n","        torch.save({\n","            'epoch': epoch,\n","            'state_dict': self.netG.state_dict(),\n","            'optimizer': self.optimizer_G.state_dict(),\n","        }, save_path_G)\n","\n","        torch.save({\n","            'epoch': epoch,\n","            'state_dict': self.netD.state_dict(),\n","            'optimizer': self.optimizer_D.state_dict(),\n","        }, save_path_D)\n","\n","        print(f\"✅ Networks saved at epoch {epoch}\")\n","\n","    def load_networks(self, epoch, save_dir):\n","        \"\"\"네트워크 로드\"\"\"\n","        load_path_G = os.path.join(save_dir, f'netG_epoch_{epoch}.pth')\n","        load_path_D = os.path.join(save_dir, f'netD_epoch_{epoch}.pth')\n","\n","        if os.path.exists(load_path_G):\n","            checkpoint_G = torch.load(load_path_G, map_location=self.device)\n","            self.netG.load_state_dict(checkpoint_G['state_dict'])\n","            self.optimizer_G.load_state_dict(checkpoint_G['optimizer'])\n","            print(f\"✅ Generator loaded from epoch {epoch}\")\n","\n","        if os.path.exists(load_path_D):\n","            checkpoint_D = torch.load(load_path_D, map_location=self.device)\n","            self.netD.load_state_dict(checkpoint_D['state_dict'])\n","            self.optimizer_D.load_state_dict(checkpoint_D['optimizer'])\n","            print(f\"✅ Discriminator loaded from epoch {epoch}\")\n","\n","    def eval(self):\n","        \"\"\"평가 모드\"\"\"\n","        self.netG.eval()\n","        self.netD.eval()\n","\n","    def train(self):\n","        \"\"\"학습 모드\"\"\"\n","        self.netG.train()\n","        self.netD.train()\n","\n","    def inference(self, xray_front, xray_side):\n","        \"\"\"\n","        추론 (학습 없이 CT 생성)\n","        Args:\n","            xray_front: [B, 1, H, W]\n","            xray_side: [B, 1, H, W]\n","        Returns:\n","            ct_fake: [B, 1, D, H, W]\n","        \"\"\"\n","        self.eval()\n","        with torch.no_grad():\n","            xray_front = xray_front.to(self.device)\n","            xray_side = xray_side.to(self.device)\n","            ct_fake = self.netG([xray_front, xray_side])\n","        return ct_fake\n","\n","\n","# ============================================================================\n","# Configuration\n","# ============================================================================\n","\n","class Options:\n","    \"\"\"학습 옵션\"\"\"\n","\n","    def __init__(self):\n","        # Network\n","        self.input_nc = 1\n","        self.output_nc = 1\n","        self.ngf = 64\n","        self.ndf = 64\n","        self.n_layers_D = 3\n","        self.depth = 256\n","\n","        # Loss weights\n","        self.lambda_GAN = 1.0\n","        self.lambda_L1 = 100.0\n","        self.lambda_Proj = 10.0\n","        self.use_proj_loss = False  # DRR 없이는 False\n","\n","        # Optimizer\n","        self.lr_G = 0.0002\n","        self.lr_D = 0.0002\n","        self.beta1 = 0.5\n","        self.beta2 = 0.999\n","\n","        # Training\n","        self.pool_size = 50\n","        self.batch_size = 1\n","        self.n_epochs = 100\n","        self.n_epochs_decay = 100\n","\n","        # Directories\n","        self.checkpoints_dir = '/content/drive/MyDrive/x2ct_checkpoints'\n","        self.save_epoch_freq = 5\n","\n","        # Display\n","        self.print_freq = 10\n","\n","\n","# ============================================================================\n","# 테스트\n","# ============================================================================\n","\n","if __name__ == \"__main__\":\n","    print(\"Testing X2CTGAN Model...\")\n","\n","    # Import networks\n","    from networks import X2CTGenerator, X2CTDiscriminator\n","\n","    # Options\n","    opt = Options()\n","\n","    # Initialize networks\n","    generator = X2CTGenerator(\n","        input_nc=opt.input_nc,\n","        output_nc=opt.output_nc,\n","        ngf=opt.ngf,\n","        depth=opt.depth\n","    )\n","\n","    discriminator = X2CTDiscriminator(\n","        input_nc=opt.output_nc,\n","        ndf=opt.ndf,\n","        n_layers=opt.n_layers_D\n","    )\n","\n","    # Initialize model\n","    model = X2CTGAN(opt, generator, discriminator)\n","\n","    # Test forward pass\n","    dummy_data = {\n","        'xray_front': torch.randn(1, 1, 256, 256),\n","        'xray_side': torch.randn(1, 1, 256, 256),\n","        'ct': torch.randn(1, 1, 256, 256, 256)\n","    }\n","\n","    model.set_input(dummy_data)\n","    model.optimize_parameters()\n","\n","    # Get losses\n","    losses = model.get_current_losses()\n","    print(f\"\\nLosses after one optimization step:\")\n","    for name, value in losses.items():\n","        print(f\"  {name}: {value:.4f}\")\n","\n","    # Test inference\n","    xray_front = torch.randn(1, 1, 256, 256)\n","    xray_side = torch.randn(1, 1, 256, 256)\n","    ct_fake = model.inference(xray_front, xray_side)\n","    print(f\"\\nInference output shape: {ct_fake.shape}\")\n","\n","    print(f\"\\n✅ X2CTGAN model working perfectly!\")"],"metadata":{"id":"TKz47UfAjvph"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","X2CT Training Script\n","완전한 학습 루프 구현\n","\"\"\"\n","\n","import torch\n","from torch.utils.data import DataLoader\n","import time\n","import os\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","\n","class Trainer:\n","    \"\"\"X2CTGAN Trainer\"\"\"\n","\n","    def __init__(self, model, train_dataset, val_dataset, opt):\n","        self.model = model\n","        self.opt = opt\n","\n","        # Data loaders\n","        self.train_loader = DataLoader(\n","            train_dataset,\n","            batch_size=opt.batch_size,\n","            shuffle=True,\n","            num_workers=0,  # Colab에서는 0으로 설정\n","            pin_memory=True if torch.cuda.is_available() else False\n","        )\n","\n","        self.val_loader = DataLoader(\n","            val_dataset,\n","            batch_size=1,\n","            shuffle=False,\n","            num_workers=0\n","        ) if val_dataset is not None else None\n","\n","        # For tracking\n","        self.total_steps = 0\n","        self.epoch_start_time = time.time()\n","\n","        # Loss history\n","        self.loss_history = {\n","            'D': [],\n","            'G_GAN': [],\n","            'G_L1': [],\n","            'G': []\n","        }\n","\n","        # Create checkpoint directory\n","        os.makedirs(opt.checkpoints_dir, exist_ok=True)\n","\n","    def train_epoch(self, epoch):\n","        \"\"\"한 에폭 학습\"\"\"\n","        self.model.train()\n","        epoch_losses = {'D': 0, 'G_GAN': 0, 'G_L1': 0, 'G': 0}\n","\n","        pbar = tqdm(self.train_loader, desc=f'Epoch {epoch}')\n","        for i, data in enumerate(pbar):\n","            self.total_steps += 1\n","\n","            # Set input and optimize\n","            self.model.set_input(data)\n","            self.model.optimize_parameters()\n","\n","            # Get losses\n","            losses = self.model.get_current_losses()\n","\n","            # Accumulate\n","            for key in epoch_losses:\n","                if key in losses:\n","                    epoch_losses[key] += losses[key]\n","\n","            # Update progress bar\n","            pbar.set_postfix({\n","                'D': f\"{losses['D']:.4f}\",\n","                'G': f\"{losses['G']:.4f}\",\n","                'G_L1': f\"{losses['G_L1']:.4f}\"\n","            })\n","\n","            # Print detailed losses\n","            if self.total_steps % self.opt.print_freq == 0:\n","                self.print_current_losses(epoch, i, losses)\n","\n","        # Average losses\n","        n_batches = len(self.train_loader)\n","        for key in epoch_losses:\n","            epoch_losses[key] /= n_batches\n","            self.loss_history[key].append(epoch_losses[key])\n","\n","        return epoch_losses\n","\n","    def validate(self, epoch):\n","        \"\"\"검증\"\"\"\n","        if self.val_loader is None:\n","            return None\n","\n","        self.model.eval()\n","        val_losses = {'D': 0, 'G_GAN': 0, 'G_L1': 0, 'G': 0}\n","\n","        with torch.no_grad():\n","            for i, data in enumerate(tqdm(self.val_loader, desc='Validation')):\n","                self.model.set_input(data)\n","                self.model.forward()\n","\n","                # Compute losses without backward\n","                pred_fake = self.model.netD(self.model.ct_fake)\n","                pred_real = self.model.netD(self.model.ct_real)\n","\n","                loss_G_GAN = self.model.criterionGAN(pred_fake, True)\n","                loss_G_L1 = self.model.criterionL1(self.model.ct_fake, self.model.ct_real)\n","                loss_D_fake = self.model.criterionGAN(pred_fake, False)\n","                loss_D_real = self.model.criterionGAN(pred_real, True)\n","\n","                val_losses['G_GAN'] += loss_G_GAN.item()\n","                val_losses['G_L1'] += loss_G_L1.item()\n","                val_losses['D'] += ((loss_D_fake + loss_D_real) * 0.5).item()\n","                val_losses['G'] += (loss_G_GAN + loss_G_L1 * self.opt.lambda_L1).item()\n","\n","        # Average\n","        n_batches = len(self.val_loader)\n","        for key in val_losses:\n","            val_losses[key] /= n_batches\n","\n","        print(f\"\\n{'='*60}\")\n","        print(f\"Validation Results at Epoch {epoch}:\")\n","        for key, value in val_losses.items():\n","            print(f\"  Val_{key}: {value:.4f}\")\n","        print(f\"{'='*60}\\n\")\n","\n","        return val_losses\n","\n","    def print_current_losses(self, epoch, iters, losses):\n","        \"\"\"현재 loss 출력\"\"\"\n","        message = f'Epoch: {epoch}, Iters: {iters}, '\n","        for k, v in losses.items():\n","            message += f'{k}: {v:.4f} '\n","        print(message)\n","\n","    def save_checkpoint(self, epoch):\n","        \"\"\"체크포인트 저장\"\"\"\n","        self.model.save_networks(epoch, self.opt.checkpoints_dir)\n","\n","    def plot_losses(self, save_path=None):\n","        \"\"\"Loss 그래프 저장\"\"\"\n","        plt.figure(figsize=(12, 8))\n","\n","        plt.subplot(2, 2, 1)\n","        plt.plot(self.loss_history['D'])\n","        plt.title('Discriminator Loss')\n","        plt.xlabel('Epoch')\n","        plt.ylabel('Loss')\n","        plt.grid(True)\n","\n","        plt.subplot(2, 2, 2)\n","        plt.plot(self.loss_history['G'])\n","        plt.title('Generator Total Loss')\n","        plt.xlabel('Epoch')\n","        plt.ylabel('Loss')\n","        plt.grid(True)\n","\n","        plt.subplot(2, 2, 3)\n","        plt.plot(self.loss_history['G_GAN'], label='GAN Loss')\n","        plt.plot(self.loss_history['G_L1'], label='L1 Loss')\n","        plt.title('Generator Loss Components')\n","        plt.xlabel('Epoch')\n","        plt.ylabel('Loss')\n","        plt.legend()\n","        plt.grid(True)\n","\n","        plt.subplot(2, 2, 4)\n","        plt.plot(self.loss_history['G_L1'])\n","        plt.title('Reconstruction Loss (L1)')\n","        plt.xlabel('Epoch')\n","        plt.ylabel('Loss')\n","        plt.grid(True)\n","\n","        plt.tight_layout()\n","\n","        if save_path:\n","            plt.savefig(save_path, dpi=150, bbox_inches='tight')\n","            print(f\"Loss plot saved to {save_path}\")\n","\n","        plt.show()\n","\n","    def visualize_results(self, epoch, num_samples=1):\n","        \"\"\"결과 시각화\"\"\"\n","        self.model.eval()\n","\n","        with torch.no_grad():\n","            for i, data in enumerate(self.val_loader if self.val_loader else self.train_loader):\n","                if i >= num_samples:\n","                    break\n","\n","                self.model.set_input(data)\n","                self.model.forward()\n","\n","                visuals = self.model.get_current_visuals()\n","\n","                # Convert to numpy\n","                xray_front = visuals['xray_front'][0, 0].cpu().numpy()\n","                xray_side = visuals['xray_side'][0, 0].cpu().numpy()\n","                ct_real = visuals['ct_real'][0, 0].cpu().numpy()\n","                ct_fake = visuals['ct_fake'][0, 0].cpu().numpy()\n","\n","                # Plot\n","                fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n","\n","                # X-rays\n","                axes[0, 0].imshow(xray_front, cmap='gray')\n","                axes[0, 0].set_title('Input X-ray (Front)')\n","                axes[0, 0].axis('off')\n","\n","                axes[0, 1].imshow(xray_side, cmap='gray')\n","                axes[0, 1].set_title('Input X-ray (Side)')\n","                axes[0, 1].axis('off')\n","\n","                # Real CT slices\n","                mid_slice = ct_real.shape[0] // 2\n","                axes[0, 2].imshow(ct_real[mid_slice], cmap='gray')\n","                axes[0, 2].set_title('Real CT (Mid Slice)')\n","                axes[0, 2].axis('off')\n","\n","                axes[0, 3].imshow(ct_real[:, mid_slice, :], cmap='gray')\n","                axes[0, 3].set_title('Real CT (Coronal)')\n","                axes[0, 3].axis('off')\n","\n","                # Fake CT slices\n","                axes[1, 0].text(0.5, 0.5, f'Epoch {epoch}',\n","                               ha='center', va='center', fontsize=16)\n","                axes[1, 0].axis('off')\n","\n","                axes[1, 1].axis('off')\n","\n","                axes[1, 2].imshow(ct_fake[mid_slice], cmap='gray')\n","                axes[1, 2].set_title('Generated CT (Mid Slice)')\n","                axes[1, 2].axis('off')\n","\n","                axes[1, 3].imshow(ct_fake[:, mid_slice, :], cmap='gray')\n","                axes[1, 3].set_title('Generated CT (Coronal)')\n","                axes[1, 3].axis('off')\n","\n","                plt.tight_layout()\n","\n","                save_path = os.path.join(\n","                    self.opt.checkpoints_dir,\n","                    f'results_epoch_{epoch}_sample_{i}.png'\n","                )\n","                plt.savefig(save_path, dpi=150, bbox_inches='tight')\n","                print(f\"Results saved to {save_path}\")\n","\n","                plt.show()\n","\n","    def train(self, start_epoch=0):\n","        \"\"\"전체 학습 루프\"\"\"\n","        print(f\"\\n{'='*60}\")\n","        print(f\"Starting Training\")\n","        print(f\"Total Epochs: {self.opt.n_epochs}\")\n","        print(f\"Batch Size: {self.opt.batch_size}\")\n","        print(f\"Device: {self.model.device}\")\n","        print(f\"{'='*60}\\n\")\n","\n","        for epoch in range(start_epoch, self.opt.n_epochs):\n","            epoch_start_time = time.time()\n","\n","            # Train\n","            train_losses = self.train_epoch(epoch)\n","\n","            # Validate\n","            if self.val_loader is not None and epoch % 5 == 0:\n","                val_losses = self.validate(epoch)\n","\n","            # Print epoch summary\n","            epoch_time = time.time() - epoch_start_time\n","            print(f\"\\nEpoch {epoch} completed in {epoch_time:.2f}s\")\n","            print(f\"Train Losses: D={train_losses['D']:.4f}, \"\n","                  f\"G={train_losses['G']:.4f}, G_L1={train_losses['G_L1']:.4f}\")\n","\n","            # Save checkpoint\n","            if (epoch + 1) % self.opt.save_epoch_freq == 0:\n","                self.save_checkpoint(epoch)\n","                self.plot_losses(\n","                    os.path.join(self.opt.checkpoints_dir, f'loss_plot_epoch_{epoch}.png')\n","                )\n","\n","            # Visualize results\n","            if (epoch + 1) % self.opt.save_epoch_freq == 0:\n","                self.visualize_results(epoch, num_samples=2)\n","\n","        print(f\"\\n{'='*60}\")\n","        print(f\"Training Completed!\")\n","        print(f\"{'='*60}\\n\")\n","\n","        # Final save\n","        self.save_checkpoint(self.opt.n_epochs - 1)\n","        self.plot_losses(\n","            os.path.join(self.opt.checkpoints_dir, 'final_loss_plot.png')\n","        )\n","\n","\n","# ============================================================================\n","# Main Training Function\n","# ============================================================================\n","\n","def main():\n","    \"\"\"메인 학습 함수\"\"\"\n","\n","    # Import필요한 모듈들\n","    from networks import X2CTGenerator, X2CTDiscriminator\n","    from model import X2CTGAN, Options\n","    from losses_and_dataset import SimpleX2CTDataset\n","    import numpy as np\n","\n","    print(\"=\"*60)\n","    print(\"X2CT-GAN Training\")\n","    print(\"=\"*60)\n","\n","    # Options\n","    opt = Options()\n","    opt.n_epochs = 50  # 테스트용으로 50 에폭\n","    opt.save_epoch_freq = 5\n","    opt.batch_size = 1\n","    opt.use_proj_loss = False  # DRR 없으면 False\n","\n","    # Create networks\n","    print(\"\\n1. Initializing networks...\")\n","    generator = X2CTGenerator(\n","        input_nc=opt.input_nc,\n","        output_nc=opt.output_nc,\n","        ngf=opt.ngf,\n","        depth=opt.depth\n","    )\n","\n","    discriminator = X2CTDiscriminator(\n","        input_nc=opt.output_nc,\n","        ndf=opt.ndf,\n","        n_layers=opt.n_layers_D\n","    )\n","\n","    # Create model\n","    print(\"2. Creating X2CTGAN model...\")\n","    model = X2CTGAN(opt, generator, discriminator)\n","\n","    # Create dummy dataset (실제 사용시 HDF5 데이터셋으로 교체)\n","    print(\"3. Loading dataset...\")\n","    # 여기서는 테스트용 더미 데이터 사용\n","    dummy_ct = np.random.randn(256, 256, 256).astype(np.float32)\n","    dummy_xray_front = np.random.randn(256, 256).astype(np.float32)\n","    dummy_xray_side = np.random.randn(256, 256).astype(np.float32)\n","\n","    train_dataset = SimpleX2CTDataset(dummy_ct, dummy_xray_front, dummy_xray_side)\n","    val_dataset = SimpleX2CTDataset(dummy_ct, dummy_xray_front, dummy_xray_side)\n","\n","    # Create trainer\n","    print(\"4. Creating trainer...\")\n","    trainer = Trainer(model, train_dataset, val_dataset, opt)\n","\n","    # Start training\n","    print(\"\\n5. Starting training...\")\n","    trainer.train(start_epoch=0)\n","\n","    print(\"\\n✅ Training completed successfully!\")\n","\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"id":"YcVzy8bXjvsS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","X2CT Testing and Inference Script\n","학습된 모델로 추론 및 평가\n","\"\"\"\n","\n","import torch\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from mpl_toolkits.mplot3d import Axes3D\n","import os\n","\n","\n","class Tester:\n","    \"\"\"X2CTGAN Tester\"\"\"\n","\n","    def __init__(self, model, test_dataset, opt):\n","        self.model = model\n","        self.opt = opt\n","        self.test_dataset = test_dataset\n","\n","        from torch.utils.data import DataLoader\n","        self.test_loader = DataLoader(\n","            test_dataset,\n","            batch_size=1,\n","            shuffle=False,\n","            num_workers=0\n","        )\n","\n","        # Metrics\n","        self.metrics = {\n","            'PSNR': [],\n","            'MSE': [],\n","            'MAE': [],\n","            'SSIM': []\n","        }\n","\n","    def compute_metrics(self, pred, target):\n","        \"\"\"메트릭 계산\"\"\"\n","        from losses_and_dataset import compute_psnr, compute_mse, compute_mae, compute_ssim\n","\n","        psnr = compute_psnr(pred, target)\n","        mse = compute_mse(pred, target)\n","        mae = compute_mae(pred, target)\n","        ssim = compute_ssim(pred, target)\n","\n","        return {\n","            'PSNR': psnr,\n","            'MSE': mse,\n","            'MAE': mae,\n","            'SSIM': ssim\n","        }\n","\n","    def test(self, visualize=True):\n","        \"\"\"테스트 실행\"\"\"\n","        print(f\"\\n{'='*60}\")\n","        print(f\"Starting Testing\")\n","        print(f\"{'='*60}\\n\")\n","\n","        self.model.eval()\n","\n","        with torch.no_grad():\n","            for i, data in enumerate(self.test_loader):\n","                print(f\"\\nProcessing sample {i+1}/{len(self.test_loader)}...\")\n","\n","                # Set input and forward\n","                self.model.set_input(data)\n","                self.model.forward()\n","\n","                # Get results\n","                visuals = self.model.get_current_visuals()\n","                ct_real = visuals['ct_real']\n","                ct_fake = visuals['ct_fake']\n","\n","                # Compute metrics\n","                metrics = self.compute_metrics(ct_fake, ct_real)\n","\n","                # Store metrics\n","                for key, value in metrics.items():\n","                    self.metrics[key].append(value)\n","\n","                # Print metrics\n","                print(f\"Metrics for sample {i+1}:\")\n","                for key, value in metrics.items():\n","                    print(f\"  {key}: {value:.4f}\")\n","\n","                # Visualize\n","                if visualize:\n","                    self.visualize_sample(\n","                        visuals,\n","                        metrics,\n","                        sample_idx=i,\n","                        save_path=os.path.join(\n","                            self.opt.checkpoints_dir,\n","                            f'test_result_sample_{i}.png'\n","                        )\n","                    )\n","\n","        # Print average metrics\n","        print(f\"\\n{'='*60}\")\n","        print(f\"Average Metrics:\")\n","        for key in self.metrics:\n","            avg = np.mean(self.metrics[key])\n","            std = np.std(self.metrics[key])\n","            print(f\"  {key}: {avg:.4f} ± {std:.4f}\")\n","        print(f\"{'='*60}\\n\")\n","\n","        return self.metrics\n","\n","    def visualize_sample(self, visuals, metrics, sample_idx=0, save_path=None):\n","        \"\"\"샘플 시각화 (다양한 뷰)\"\"\"\n","        # Convert to numpy\n","        xray_front = visuals['xray_front'][0, 0].cpu().numpy()\n","        xray_side = visuals['xray_side'][0, 0].cpu().numpy()\n","        ct_real = visuals['ct_real'][0, 0].cpu().numpy()\n","        ct_fake = visuals['ct_fake'][0, 0].cpu().numpy()\n","\n","        # Create figure\n","        fig = plt.figure(figsize=(20, 12))\n","\n","        # 1. Input X-rays\n","        ax1 = plt.subplot(3, 5, 1)\n","        ax1.imshow(xray_front, cmap='gray')\n","        ax1.set_title('Input X-ray (Front View)', fontsize=12)\n","        ax1.axis('off')\n","\n","        ax2 = plt.subplot(3, 5, 2)\n","        ax2.imshow(xray_side, cmap='gray')\n","        ax2.set_title('Input X-ray (Side View)', fontsize=12)\n","        ax2.axis('off')\n","\n","        # 2. Real CT - Different slices\n","        mid_d = ct_real.shape[0] // 2\n","        mid_h = ct_real.shape[1] // 2\n","        mid_w = ct_real.shape[2] // 2\n","\n","        ax3 = plt.subplot(3, 5, 3)\n","        ax3.imshow(ct_real[mid_d, :, :], cmap='gray')\n","        ax3.set_title('Real CT (Axial)', fontsize=12)\n","        ax3.axis('off')\n","\n","        ax4 = plt.subplot(3, 5, 4)\n","        ax4.imshow(ct_real[:, mid_h, :], cmap='gray')\n","        ax4.set_title('Real CT (Coronal)', fontsize=12)\n","        ax4.axis('off')\n","\n","        ax5 = plt.subplot(3, 5, 5)\n","        ax5.imshow(ct_real[:, :, mid_w], cmap='gray')\n","        ax5.set_title('Real CT (Sagittal)', fontsize=12)\n","        ax5.axis('off')\n","\n","        # 3. Fake CT - Different slices\n","        ax6 = plt.subplot(3, 5, 8)\n","        ax6.imshow(ct_fake[mid_d, :, :], cmap='gray')\n","        ax6.set_title('Generated CT (Axial)', fontsize=12)\n","        ax6.axis('off')\n","\n","        ax7 = plt.subplot(3, 5, 9)\n","        ax7.imshow(ct_fake[:, mid_h, :], cmap='gray')\n","        ax7.set_title('Generated CT (Coronal)', fontsize=12)\n","        ax7.axis('off')\n","\n","        ax8 = plt.subplot(3, 5, 10)\n","        ax8.imshow(ct_fake[:, :, mid_w], cmap='gray')\n","        ax8.set_title('Generated CT (Sagittal)', fontsize=12)\n","        ax8.axis('off')\n","\n","        # 4. Difference maps\n","        diff = np.abs(ct_real - ct_fake)\n","\n","        ax9 = plt.subplot(3, 5, 13)\n","        im = ax9.imshow(diff[mid_d, :, :], cmap='hot')\n","        ax9.set_title('Difference (Axial)', fontsize=12)\n","        ax9.axis('off')\n","        plt.colorbar(im, ax=ax9, fraction=0.046)\n","\n","        ax10 = plt.subplot(3, 5, 14)\n","        im = ax10.imshow(diff[:, mid_h, :], cmap='hot')\n","        ax10.set_title('Difference (Coronal)', fontsize=12)\n","        ax10.axis('off')\n","        plt.colorbar(im, ax=ax10, fraction=0.046)\n","\n","        ax11 = plt.subplot(3, 5, 15)\n","        im = ax11.imshow(diff[:, :, mid_w], cmap='hot')\n","        ax11.set_title('Difference (Sagittal)', fontsize=12)\n","        ax11.axis('off')\n","        plt.colorbar(im, ax=ax11, fraction=0.046)\n","\n","        # 5. Metrics text\n","        ax_text = plt.subplot(3, 5, 6)\n","        ax_text.axis('off')\n","        metrics_text = f\"Sample {sample_idx+1} Metrics:\\n\\n\"\n","        for key, value in metrics.items():\n","            metrics_text += f\"{key}: {value:.4f}\\n\"\n","        ax_text.text(0.1, 0.5, metrics_text, fontsize=14,\n","                    verticalalignment='center', family='monospace')\n","\n","        plt.suptitle(f'X2CT-GAN Test Results - Sample {sample_idx+1}',\n","                     fontsize=16, fontweight='bold')\n","        plt.tight_layout()\n","\n","        if save_path:\n","            plt.savefig(save_path, dpi=150, bbox_inches='tight')\n","            print(f\"  Visualization saved to {save_path}\")\n","\n","        plt.show()\n","\n","    def save_3d_volume(self, ct_volume, save_path):\n","        \"\"\"3D 볼륨을 .npy 파일로 저장\"\"\"\n","        np.save(save_path, ct_volume)\n","        print(f\"3D volume saved to {save_path}\")\n","\n","\n","def inference_single_sample(model, xray_front, xray_side, visualize=True):\n","    \"\"\"\n","    단일 샘플 추론\n","\n","    Args:\n","        model: 학습된 X2CTGAN 모델\n","        xray_front: [1, 256, 256] numpy array\n","        xray_side: [1, 256, 256] numpy array\n","        visualize: 시각화 여부\n","\n","    Returns:\n","        ct_fake: [1, 256, 256, 256] numpy array\n","    \"\"\"\n","    model.eval()\n","\n","    # Convert to torch tensors\n","    xray_front_tensor = torch.from_numpy(xray_front).float().unsqueeze(0).unsqueeze(0)\n","    xray_side_tensor = torch.from_numpy(xray_side).float().unsqueeze(0).unsqueeze(0)\n","\n","    # Inference\n","    with torch.no_grad():\n","        ct_fake = model.inference(xray_front_tensor, xray_side_tensor)\n","\n","    # Convert to numpy\n","    ct_fake_np = ct_fake[0, 0].cpu().numpy()\n","\n","    if visualize:\n","        # Quick visualization\n","        fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n","\n","        # Inputs\n","        axes[0, 0].imshow(xray_front, cmap='gray')\n","        axes[0, 0].set_title('Input: Front X-ray')\n","        axes[0, 0].axis('off')\n","\n","        axes[0, 1].imshow(xray_side, cmap='gray')\n","        axes[0, 1].set_title('Input: Side X-ray')\n","        axes[0, 1].axis('off')\n","\n","        axes[0, 2].axis('off')\n","\n","        # Output CT slices\n","        mid = ct_fake_np.shape[0] // 2\n","\n","        axes[1, 0].imshow(ct_fake_np[mid, :, :], cmap='gray')\n","        axes[1, 0].set_title('Output: CT (Axial)')\n","        axes[1, 0].axis('off')\n","\n","        axes[1, 1].imshow(ct_fake_np[:, mid, :], cmap='gray')\n","        axes[1, 1].set_title('Output: CT (Coronal)')\n","        axes[1, 1].axis('off')\n","\n","        axes[1, 2].imshow(ct_fake_np[:, :, mid], cmap='gray')\n","        axes[1, 2].set_title('Output: CT (Sagittal)')\n","        axes[1, 2].axis('off')\n","\n","        plt.suptitle('X2CT-GAN Inference Result', fontsize=16, fontweight='bold')\n","        plt.tight_layout()\n","        plt.show()\n","\n","    return ct_fake_np\n","\n","\n","# ============================================================================\n","# Main Test Function\n","# ============================================================================\n","\n","def main():\n","    \"\"\"메인 테스트 함수\"\"\"\n","\n","    # Import 필요한 모듈들\n","    from networks import X2CTGenerator, X2CTDiscriminator\n","    from model import X2CTGAN, Options\n","    from losses_and_dataset import SimpleX2CTDataset\n","    import numpy as np\n","\n","    print(\"=\"*60)\n","    print(\"X2CT-GAN Testing\")\n","    print(\"=\"*60)\n","\n","    # Options\n","    opt = Options()\n","\n","    # Create networks\n","    print(\"\\n1. Initializing networks...\")\n","    generator = X2CTGenerator(\n","        input_nc=opt.input_nc,\n","        output_nc=opt.output_nc,\n","        ngf=opt.ngf,\n","        depth=opt.depth\n","    )\n","\n","    discriminator = X2CTDiscriminator(\n","        input_nc=opt.output_nc,\n","        ndf=opt.ndf,\n","        n_layers=opt.n_layers_D\n","    )\n","\n","    # Create model\n","    print(\"2. Creating X2CTGAN model...\")\n","    model = X2CTGAN(opt, generator, discriminator)\n","\n","    # Load trained model (if available)\n","    # model.load_networks(epoch=50, save_dir=opt.checkpoints_dir)\n","\n","    # Create test dataset (실제 사용시 HDF5 데이터셋으로 교체)\n","    print(\"3. Loading test dataset...\")\n","    dummy_ct = np.random.randn(256, 256, 256).astype(np.float32)\n","    dummy_xray_front = np.random.randn(256, 256).astype(np.float32)\n","    dummy_xray_side = np.random.randn(256, 256).astype(np.float32)\n","\n","    test_dataset = SimpleX2CTDataset(dummy_ct, dummy_xray_front, dummy_xray_side)\n","\n","    # Create tester\n","    print(\"4. Creating tester...\")\n","    tester = Tester(model, test_dataset, opt)\n","\n","    # Run test\n","    print(\"\\n5. Running test...\")\n","    metrics = tester.test(visualize=True)\n","\n","    print(\"\\n✅ Testing completed successfully!\")\n","\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"id":"oMX7KFCijvu-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","X2CT-GAN Complete Pipeline\n","사용자 데이터로 전체 파이프라인 실행\n","\n","사용법:\n","1. Google Colab에서 실행\n","2. Google Drive 마운트\n","3. 데이터 경로 설정\n","4. 전체 파이프라인 실행\n","\"\"\"\n","\n","import sys\n","import os\n","\n","# Add current directory to path\n","sys.path.append('/home/claude/x2ct_complete')\n","\n","import torch\n","import numpy as np\n","\n","\n","# ============================================================================\n","# STEP 1: 데이터 전처리\n","# ============================================================================\n","\n","def step1_preprocess_data():\n","    \"\"\"데이터 전처리 및 HDF5 저장\"\"\"\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"STEP 1: Data Preprocessing\")\n","    print(\"=\"*60)\n","\n","    from data_preprocessing import CTPreprocessor, XRayPreprocessor, HDF5DataCreator\n","\n","    # 경로 설정 (사용자의 실제 경로로 변경)\n","    ct_folder = '/content/drive/MyDrive/LIDC-IDRI/LIDC-IDRI-0001/01-01-2000-NA-NA-30178/3000566.000000-NA-03192'\n","    xray_front_path = '/content/drive/MyDrive/LIDC-IDRI/LIDC-IDRI-0001/01-01-2000-NA-NA-35511/3000923.000000-NA-62357/1-1.dcm'\n","    xray_side_path = '/content/drive/MyDrive/LIDC-IDRI/LIDC-IDRI-0001/01-01-2000-NA-NA-35511/3000923.000000-NA-62357/1-2.dcm'\n","    output_dir = '/content/drive/MyDrive/x2ct_processed_data'\n","\n","    # Create output directory\n","    os.makedirs(output_dir, exist_ok=True)\n","\n","    # CT 전처리\n","    print(\"\\n1.1 Processing CT volume...\")\n","    ct_preprocessor = CTPreprocessor(target_size=256)\n","    ct_volume = ct_preprocessor.preprocess(ct_folder)\n","\n","    # X-ray 전처리\n","    print(\"\\n1.2 Processing X-ray images...\")\n","    xray_preprocessor = XRayPreprocessor(target_size=256)\n","    xray_front = xray_preprocessor.preprocess(xray_front_path)\n","    xray_side = xray_preprocessor.preprocess(xray_side_path)\n","\n","    # HDF5 저장\n","    print(\"\\n1.3 Saving to HDF5...\")\n","    hdf5_path = os.path.join(output_dir, 'patient_0001.h5')\n","    hdf5_creator = HDF5DataCreator(hdf5_path)\n","    hdf5_creator.create_hdf5(ct_volume, xray_front, xray_side, 'LIDC-IDRI-0001')\n","\n","    print(f\"\\n✅ Step 1 완료! 데이터 저장 위치: {hdf5_path}\")\n","\n","    return ct_volume, xray_front, xray_side, hdf5_path\n","\n","\n","# ============================================================================\n","# STEP 2: 네트워크 초기화\n","# ============================================================================\n","\n","def step2_initialize_networks():\n","    \"\"\"네트워크 초기화\"\"\"\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"STEP 2: Network Initialization\")\n","    print(\"=\"*60)\n","\n","    from networks import X2CTGenerator, X2CTDiscriminator\n","    from model import X2CTGAN, Options\n","\n","    # Options\n","    opt = Options()\n","    opt.n_epochs = 20  # 테스트용으로 20 에폭\n","    opt.save_epoch_freq = 5\n","    opt.batch_size = 1\n","    opt.use_proj_loss = False\n","    opt.checkpoints_dir = '/content/drive/MyDrive/x2ct_checkpoints'\n","\n","    # 디렉토리 생성\n","    os.makedirs(opt.checkpoints_dir, exist_ok=True)\n","\n","    # Networks\n","    print(\"\\n2.1 Creating Generator...\")\n","    generator = X2CTGenerator(\n","        input_nc=opt.input_nc,\n","        output_nc=opt.output_nc,\n","        ngf=opt.ngf,\n","        depth=opt.depth\n","    )\n","    print(f\"   Generator parameters: {sum(p.numel() for p in generator.parameters()):,}\")\n","\n","    print(\"\\n2.2 Creating Discriminator...\")\n","    discriminator = X2CTDiscriminator(\n","        input_nc=opt.output_nc,\n","        ndf=opt.ndf,\n","        n_layers=opt.n_layers_D\n","    )\n","    print(f\"   Discriminator parameters: {sum(p.numel() for p in discriminator.parameters()):,}\")\n","\n","    # Model\n","    print(\"\\n2.3 Creating X2CTGAN model...\")\n","    model = X2CTGAN(opt, generator, discriminator)\n","\n","    print(f\"\\n✅ Step 2 완료! Device: {model.device}\")\n","\n","    return model, opt\n","\n","\n","# ============================================================================\n","# STEP 3: 학습\n","# ============================================================================\n","\n","def step3_train(model, opt, ct_volume, xray_front, xray_side):\n","    \"\"\"모델 학습\"\"\"\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"STEP 3: Training\")\n","    print(\"=\"*60)\n","\n","    from train import Trainer\n","    from losses_and_dataset import SimpleX2CTDataset\n","\n","    # Dataset 생성\n","    print(\"\\n3.1 Creating datasets...\")\n","    train_dataset = SimpleX2CTDataset(ct_volume, xray_front, xray_side)\n","    val_dataset = SimpleX2CTDataset(ct_volume, xray_front, xray_side)\n","\n","    print(f\"   Train samples: {len(train_dataset)}\")\n","    print(f\"   Val samples: {len(val_dataset)}\")\n","\n","    # Trainer 생성\n","    print(\"\\n3.2 Creating trainer...\")\n","    trainer = Trainer(model, train_dataset, val_dataset, opt)\n","\n","    # 학습 시작\n","    print(\"\\n3.3 Starting training...\")\n","    trainer.train(start_epoch=0)\n","\n","    print(f\"\\n✅ Step 3 완료! 체크포인트 저장 위치: {opt.checkpoints_dir}\")\n","\n","    return trainer\n","\n","\n","# ============================================================================\n","# STEP 4: 테스트 및 추론\n","# ============================================================================\n","\n","def step4_test(model, opt, ct_volume, xray_front, xray_side):\n","    \"\"\"모델 테스트 및 추론\"\"\"\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"STEP 4: Testing and Inference\")\n","    print(\"=\"*60)\n","\n","    from test import Tester, inference_single_sample\n","    from losses_and_dataset import SimpleX2CTDataset\n","\n","    # Test dataset\n","    print(\"\\n4.1 Creating test dataset...\")\n","    test_dataset = SimpleX2CTDataset(ct_volume, xray_front, xray_side)\n","\n","    # Tester\n","    print(\"\\n4.2 Running comprehensive test...\")\n","    tester = Tester(model, test_dataset, opt)\n","    metrics = tester.test(visualize=True)\n","\n","    # Single inference\n","    print(\"\\n4.3 Running single inference...\")\n","    ct_generated = inference_single_sample(\n","        model,\n","        xray_front,\n","        xray_side,\n","        visualize=True\n","    )\n","\n","    # 결과 저장\n","    save_path = os.path.join(opt.checkpoints_dir, 'generated_ct.npy')\n","    np.save(save_path, ct_generated)\n","    print(f\"\\n✅ Step 4 완료! 생성된 CT 저장 위치: {save_path}\")\n","\n","    return ct_generated, metrics\n","\n","\n","# ============================================================================\n","# STEP 5: 결과 시각화\n","# ============================================================================\n","\n","def step5_visualize_results(ct_real, ct_generated, xray_front, xray_side):\n","    \"\"\"최종 결과 시각화\"\"\"\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"STEP 5: Final Visualization\")\n","    print(\"=\"*60)\n","\n","    import matplotlib.pyplot as plt\n","    from mpl_toolkits.mplot3d import Axes3D\n","\n","    # 2D 슬라이스 비교\n","    print(\"\\n5.1 Creating 2D slice comparisons...\")\n","    fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n","\n","    mid_d = ct_real.shape[0] // 2\n","    mid_h = ct_real.shape[1] // 2\n","    mid_w = ct_real.shape[2] // 2\n","\n","    # Inputs\n","    axes[0, 0].imshow(xray_front, cmap='gray')\n","    axes[0, 0].set_title('Input: Front X-ray', fontsize=14, fontweight='bold')\n","    axes[0, 0].axis('off')\n","\n","    axes[0, 1].imshow(xray_side, cmap='gray')\n","    axes[0, 1].set_title('Input: Side X-ray', fontsize=14, fontweight='bold')\n","    axes[0, 1].axis('off')\n","\n","    axes[0, 2].axis('off')\n","    axes[0, 3].axis('off')\n","\n","    # Real CT\n","    axes[1, 0].imshow(ct_real[mid_d, :, :], cmap='gray')\n","    axes[1, 0].set_title('Real CT: Axial', fontsize=12)\n","    axes[1, 0].axis('off')\n","\n","    axes[1, 1].imshow(ct_real[:, mid_h, :], cmap='gray')\n","    axes[1, 1].set_title('Real CT: Coronal', fontsize=12)\n","    axes[1, 1].axis('off')\n","\n","    axes[1, 2].imshow(ct_real[:, :, mid_w], cmap='gray')\n","    axes[1, 2].set_title('Real CT: Sagittal', fontsize=12)\n","    axes[1, 2].axis('off')\n","\n","    axes[1, 3].text(0.5, 0.5, 'Ground Truth', ha='center', va='center',\n","                   fontsize=16, fontweight='bold')\n","    axes[1, 3].axis('off')\n","\n","    # Generated CT\n","    axes[2, 0].imshow(ct_generated[mid_d, :, :], cmap='gray')\n","    axes[2, 0].set_title('Generated CT: Axial', fontsize=12)\n","    axes[2, 0].axis('off')\n","\n","    axes[2, 1].imshow(ct_generated[:, mid_h, :], cmap='gray')\n","    axes[2, 1].set_title('Generated CT: Coronal', fontsize=12)\n","    axes[2, 1].axis('off')\n","\n","    axes[2, 2].imshow(ct_generated[:, :, mid_w], cmap='gray')\n","    axes[2, 2].set_title('Generated CT: Sagittal', fontsize=12)\n","    axes[2, 2].axis('off')\n","\n","    axes[2, 3].text(0.5, 0.5, 'Generated', ha='center', va='center',\n","                   fontsize=16, fontweight='bold', color='blue')\n","    axes[2, 3].axis('off')\n","\n","    plt.suptitle('X2CT-GAN: Complete 3D Reconstruction Results',\n","                 fontsize=18, fontweight='bold')\n","    plt.tight_layout()\n","    plt.show()\n","\n","    # 3D 볼륨 렌더링 (간단한 버전)\n","    print(\"\\n5.2 Creating 3D volume rendering...\")\n","    fig = plt.figure(figsize=(16, 6))\n","\n","    # Real CT 3D\n","    ax1 = fig.add_subplot(121, projection='3d')\n","\n","    # 샘플링 (메모리 절약)\n","    step = 8\n","    x, y, z = np.mgrid[0:ct_real.shape[0]:step,\n","                       0:ct_real.shape[1]:step,\n","                       0:ct_real.shape[2]:step]\n","\n","    values = ct_real[::step, ::step, ::step]\n","    colors = plt.cm.gray(values / values.max())\n","\n","    ax1.voxels(values > 0.5, facecolors=colors, edgecolor='none', alpha=0.5)\n","    ax1.set_title('Real CT (3D)', fontsize=14, fontweight='bold')\n","    ax1.set_xlabel('X')\n","    ax1.set_ylabel('Y')\n","    ax1.set_zlabel('Z')\n","\n","    # Generated CT 3D\n","    ax2 = fig.add_subplot(122, projection='3d')\n","\n","    values_gen = ct_generated[::step, ::step, ::step]\n","    colors_gen = plt.cm.gray(values_gen / values_gen.max())\n","\n","    ax2.voxels(values_gen > 0.5, facecolors=colors_gen, edgecolor='none', alpha=0.5)\n","    ax2.set_title('Generated CT (3D)', fontsize=14, fontweight='bold')\n","    ax2.set_xlabel('X')\n","    ax2.set_ylabel('Y')\n","    ax2.set_zlabel('Z')\n","\n","    plt.suptitle('3D Volume Rendering', fontsize=16, fontweight='bold')\n","    plt.tight_layout()\n","    plt.show()\n","\n","    print(f\"\\n✅ Step 5 완료!\")\n","\n","\n","# ============================================================================\n","# 전체 파이프라인 실행\n","# ============================================================================\n","\n","def run_complete_pipeline():\n","    \"\"\"전체 파이프라인 한번에 실행\"\"\"\n","    print(\"\\n\" + \"=\"*80)\n","    print(\" \"*20 + \"X2CT-GAN COMPLETE PIPELINE\")\n","    print(\"=\"*80)\n","    print(\"\\n이 스크립트는 다음을 수행합니다:\")\n","    print(\"1. 데이터 전처리 (CT + X-rays)\")\n","    print(\"2. 네트워크 초기화 (Generator + Discriminator)\")\n","    print(\"3. GAN 학습\")\n","    print(\"4. 테스트 및 추론\")\n","    print(\"5. 결과 시각화\")\n","    print(\"\\n\" + \"=\"*80)\n","\n","    try:\n","        # Step 1: 데이터 전처리\n","        ct_volume, xray_front, xray_side, hdf5_path = step1_preprocess_data()\n","\n","        # Step 2: 네트워크 초기화\n","        model, opt = step2_initialize_networks()\n","\n","        # Step 3: 학습\n","        trainer = step3_train(model, opt, ct_volume, xray_front, xray_side)\n","\n","        # Step 4: 테스트\n","        ct_generated, metrics = step4_test(model, opt, ct_volume, xray_front, xray_side)\n","\n","        # Step 5: 최종 시각화\n","        step5_visualize_results(ct_volume, ct_generated, xray_front, xray_side)\n","\n","        # 최종 요약\n","        print(\"\\n\" + \"=\"*80)\n","        print(\" \"*25 + \"🎉 파이프라인 완료! 🎉\")\n","        print(\"=\"*80)\n","        print(f\"\\n최종 결과:\")\n","        print(f\"  - HDF5 데이터: {hdf5_path}\")\n","        print(f\"  - 체크포인트: {opt.checkpoints_dir}\")\n","        print(f\"  - 생성된 CT shape: {ct_generated.shape}\")\n","        print(f\"\\n최종 메트릭:\")\n","        for key, values in metrics.items():\n","            print(f\"  {key}: {np.mean(values):.4f}\")\n","        print(\"\\n\" + \"=\"*80)\n","\n","        return model, ct_generated, metrics\n","\n","    except Exception as e:\n","        print(f\"\\n❌ 에러 발생: {e}\")\n","        import traceback\n","        traceback.print_exc()\n","        return None, None, None\n","\n","\n","# ============================================================================\n","# Main\n","# ============================================================================\n","\n","if __name__ == \"__main__\":\n","    # Google Colab 환경 확인\n","    try:\n","        import google.colab\n","        IN_COLAB = True\n","        print(\"✅ Google Colab 환경 감지\")\n","\n","        # Drive 마운트\n","        from google.colab import drive\n","        drive.mount('/content/drive')\n","\n","    except:\n","        IN_COLAB = False\n","        print(\"⚠️  로컬 환경에서 실행 중\")\n","\n","    # 전체 파이프라인 실행\n","    model, ct_generated, metrics = run_complete_pipeline()\n","\n","    if model is not None:\n","        print(\"\\n✅ 모든 작업이 성공적으로 완료되었습니다!\")\n","        print(\"\\n다음 단계:\")\n","        print(\"1. 생성된 CT 볼륨을 확인하세요\")\n","        print(\"2. 체크포인트를 사용하여 새로운 X-ray로 추론하세요\")\n","        print(\"3. 더 많은 데이터로 재학습하세요\")\n","    else:\n","        print(\"\\n❌ 파이프라인 실행 중 문제가 발생했습니다\")\n","        print(\"   위의 에러 메시지를 확인하세요\")"],"metadata":{"id":"srZye4onj3S0"},"execution_count":null,"outputs":[]}]}